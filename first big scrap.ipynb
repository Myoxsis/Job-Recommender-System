{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config\n",
    "\n",
    "# Create Backup\n",
    "# --------------------\n",
    "\n",
    "os.system(\"mkdir backup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "#    []   scrapRichemont()                     #    []   scrapRichemont()\n",
    "#    []   scrapDassaultAviation()              #    []   scrapRichemont()\n",
    "#    []   scrapAirFrance()                     #    []   scrapRichemont()\n",
    "#    []   scrapSanofi()                        #    []   scrapRichemont()\n",
    "#    []   scrapHermes()                        #    []   scrapRichemont()\n",
    "#    []   scrapFramatome()                     #    []   scrapRichemont()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrap Richemont\n",
    "def scrapRichemont():\n",
    "    richemont_job_db = []\n",
    "    r = requests.get('https://jobs.richemont.com/search/?q=&sortColumn=referencedate&sortDirection=desc&optionsFacetsDD_country=FR&startrow=1')\n",
    "    soup = BeautifulSoup(r.content.decode(\"utf-8\"),'lxml')\n",
    "\n",
    "    for x in soup.find_all('tr', attrs={'class' : 'data-row clickable'}):\n",
    "        row_scrap = []\n",
    "        job_title = x.find('span', attrs={'class' : 'jobTitle'}).text.replace('\\n', '')\n",
    "        job_link = x.find('span', attrs={'class' : 'jobTitle'}).find('a')['href']\n",
    "        company = x.find('span', attrs={'class' : 'jobFacility'}).text.replace('\\n', '')\n",
    "        departement = x.find('span', attrs={'class' : 'jobDepartment'}).text.replace('\\n', '')\n",
    "        location = x.find('span', attrs={'class' : 'jobLocation'}).text.replace('\\n', '').strip()\n",
    "        row_scrap.append(job_title)\n",
    "        row_scrap.append(job_link)\n",
    "        row_scrap.append(company)\n",
    "        row_scrap.append(departement)\n",
    "        row_scrap.append(location)\n",
    "        richemont_job_db.append(row_scrap)\n",
    "\n",
    "    i = 14\n",
    "    while i <= int(soup.find('a', class_='paginationItemLast')['href'][-3:]) :\n",
    "        r = requests.get(f'https://jobs.richemont.com/search/?q=&sortColumn=referencedate&sortDirection=desc&optionsFacetsDD_country=FR&startrow={i}')\n",
    "\n",
    "        soup = BeautifulSoup(r.content.decode(\"utf-8\"),'lxml')\n",
    "\n",
    "        for x in soup.find_all('tr', attrs={'class' : 'data-row clickable'}):\n",
    "            row_scrap = []\n",
    "            job_title = x.find('span', attrs={'class' : 'jobTitle'}).text.replace('\\n', '')\n",
    "            job_link = x.find('span', attrs={'class' : 'jobTitle'}).find('a')['href']\n",
    "            company = x.find('span', attrs={'class' : 'jobFacility'}).text.replace('\\n', '')\n",
    "            departement = x.find('span', attrs={'class' : 'jobDepartment'}).text.replace('\\n', '')\n",
    "            location = x.find('span', attrs={'class' : 'jobLocation'}).text.replace('\\n', '').strip()\n",
    "            row_scrap.append(job_title)\n",
    "            row_scrap.append(job_link)\n",
    "            row_scrap.append(company)\n",
    "            row_scrap.append(departement)\n",
    "            row_scrap.append(location)\n",
    "            richemont_job_db.append(row_scrap)\n",
    "        i = i + 14\n",
    "\n",
    "    richemont_job_db = pd.DataFrame(richemont_job_db)\n",
    "    richemont_job_db = richemont_job_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\",\n",
    "                                                        3 : \"Department\", 4 : \"Location\"})\n",
    "    richemont_job_db['desc'] = ''\n",
    "\n",
    "    # Add Desc to job offer\n",
    "    # add https://jobs.richemont.com before links to connect\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i <= len(richemont_job_db)-1:\n",
    "        r = requests.get('https://jobs.richemont.com' + richemont_job_db['link'][i])\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        richemont_job_db['desc'][i] = soup.find('span', class_=\"jobdescription\").text\n",
    "        i = i + 1\n",
    "    #df = pd.concat([df, richemont_job_db], axis=0)\n",
    "    print(\"Richemont Scrap Finished\")\n",
    "    \n",
    "#Scrap Dassault Aviation\n",
    "def scrapDassaultAviation():\n",
    "    dassaultAviation_db = []\n",
    "\n",
    "    i = 1\n",
    "    while i <= 10:\n",
    "        r = requests.get(f'https://carriere.dassault-aviation.com/offre-de-emploi/liste-offres.aspx?page={i}&LCID=1036')\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "        for x in soup.find_all('li', class_='ts-offer-list-item'):\n",
    "                row_scrap = []\n",
    "                job_title = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'}).text.replace('\\n', '').strip()\n",
    "                job_link = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'})['href']\n",
    "                company = \"Dassault Aviation\"\n",
    "                departement = 'N/A'\n",
    "                details = x.find('ul', attrs={'class' : 'ts-offer-list-item__description'}).find_all('li')\n",
    "\n",
    "                row_scrap.append(job_title)\n",
    "                row_scrap.append(job_link)\n",
    "                row_scrap.append(company)\n",
    "                row_scrap.append(departement)\n",
    "                row_scrap.append(details)\n",
    "\n",
    "                dassaultAviation_db.append(row_scrap)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    dassaultAviation_db = pd.DataFrame(dassaultAviation_db)\n",
    "    dassaultAviation_db = dassaultAviation_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    dassaultAviation_db['desc'] = ''\n",
    "\n",
    "    # Add Desc to job offer\n",
    "    # add https://carriere.dassault-aviation.com before links to connect\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(dassaultAviation_db)-1:\n",
    "        r = requests.get('https://carriere.dassault-aviation.com' + dassaultAviation_db['link'][i])\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        dassaultAviation_db['desc'][i] = soup.find('div', attrs={'id' : 'contenu-ficheoffre'}).text\n",
    "        i = i + 1\n",
    "    #df = pd.concat([df, dassaultAviation_db], axis=0)\n",
    "    print(\"Dassault Aviation Scrap Finished\")\n",
    "    \n",
    "# Scrap Air France\n",
    "def scrapAirFrance():\n",
    "    airFrance_db = []\n",
    "\n",
    "    r = requests.get('https://recrutement.airfrance.com/offre-de-emploi/liste-offres.aspx')\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "    for x in soup.find_all('li', class_='ts-offer-list-item'):\n",
    "                row_scrap = []\n",
    "                job_title = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'}).text.replace('\\n', '').strip()\n",
    "                job_link = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'})['href']\n",
    "                company = \"Air France\"\n",
    "                departement = 'N/A'\n",
    "                details = x.find('ul', attrs={'class' : 'ts-offer-list-item__description'}).find_all('li')\n",
    "\n",
    "                row_scrap.append(job_title)\n",
    "                row_scrap.append(job_link)\n",
    "                row_scrap.append(company)\n",
    "                row_scrap.append(departement)\n",
    "                row_scrap.append(details)\n",
    "\n",
    "                airFrance_db.append(row_scrap)\n",
    "\n",
    "    airFrance_db = pd.DataFrame(airFrance_db)\n",
    "    airFrance_db = airFrance_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    airFrance_db['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(airFrance_db)-1:\n",
    "        r = requests.get('https://recrutement.airfrance.com' + airFrance_db['link'][i])\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        airFrance_db['desc'][i] = soup.find('div', attrs={'id' : 'contenu-ficheoffre'}).text\n",
    "        i = i + 1\n",
    "    #df = pd.concat([df, airFrance_db], axis=0)\n",
    "    print(\"Air France Scrap Finished\")\n",
    "\n",
    "# Scrap Sanofi\n",
    "def scrapSanofi():\n",
    "    r = requests.get('https://fr.jobs.sanofi.com/recherche-d%27offres/?p=1')\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "    sanofi_db = []\n",
    "\n",
    "    i = 1\n",
    "    while i <= int(soup.find('input', class_='pagination-current')['max']):\n",
    "        r = requests.get(f'https://fr.jobs.sanofi.com/recherche-d%27offres/?p={i}')\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        for x in soup.find('ul', class_='unstyled-list job-list').find_all('li'):\n",
    "                    row_scrap = []\n",
    "                    job_title = x.find('h2', attrs={'class' : 'h3-style'}).text.replace('\\n', '').strip()\n",
    "                    job_link = x.find('a')['href']\n",
    "                    company = \"Sanofi\"\n",
    "                    departement = 'N/A'\n",
    "                    details = x.find('span', attrs={'class' : 'job-location'}).text\n",
    "\n",
    "                    row_scrap.append(job_title)\n",
    "                    row_scrap.append(job_link)\n",
    "                    row_scrap.append(company)\n",
    "                    row_scrap.append(departement)\n",
    "                    row_scrap.append(details)\n",
    "\n",
    "                    sanofi_db.append(row_scrap)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    sanofi_db = pd.DataFrame(sanofi_db)\n",
    "    sanofi_db = sanofi_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    sanofi_db['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(sanofi_db)-1:\n",
    "        r = requests.get('https://fr.jobs.sanofi.com/' + sanofi_db['link'][i])\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        try :\n",
    "            sanofi_db['desc'][i] = soup.find('div', attrs={'class' : 'ats-description'}).text\n",
    "        except :\n",
    "            sanofi_db['desc'][i] = ''\n",
    "        i = i + 1\n",
    "    #df = pd.concat([df, sanofi_db], axis=0)\n",
    "    print(\"Sanofi Scrap Finished\")\n",
    "\n",
    "# Scrap Hermes\n",
    "def scrapHermes():\n",
    "    r = requests.get('https://talents.hermes.com/fr/')\n",
    "    soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "    hermes_db = []\n",
    "\n",
    "    for x in soup.find_all('div', class_='card-block'):\n",
    "                    row_scrap = []\n",
    "                    job_title = x.find('h2', attrs={'class' : 'offer-description bd-highlight block-with-text'}).text.replace('\\n', '').strip()\n",
    "                    job_link = x.find('a')['href']\n",
    "                    company = \"Hermes\"\n",
    "                    departement = 'N/A'\n",
    "                    details = []\n",
    "                    for v in x.find('ul', attrs={'class' : 'offer-list_info'}).find_all('li'): \n",
    "                        item = v.text\n",
    "                        details.append(item)\n",
    "\n",
    "                    #details.append(details_item)\n",
    "\n",
    "                    row_scrap.append(job_title)\n",
    "                    row_scrap.append(job_link)\n",
    "                    row_scrap.append(company)\n",
    "                    row_scrap.append(departement)\n",
    "                    row_scrap.append(details)\n",
    "\n",
    "                    hermes_db.append(row_scrap)\n",
    "\n",
    "    hermes_db = pd.DataFrame(hermes_db)\n",
    "    hermes_db = hermes_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    hermes_db['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(hermes_db)-1:\n",
    "        r = requests.get('https://talents.hermes.com/' + hermes_db['link'][i])\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        try :\n",
    "            hermes_db['desc'][i] = soup.find('div', attrs={'id' : 'detailOffer'}).text\n",
    "        except :\n",
    "            hermes_db['desc'][i] = ''\n",
    "        i = i + 1\n",
    "    #df = pd.concat([df, hermes_db], axis=0)\n",
    "    print(\"Hermes Scrap Finished\")\n",
    "\n",
    "def scrapFramatome():\n",
    "    framatome_db = []\n",
    "\n",
    "    i = 1\n",
    "    while i <= 44:\n",
    "        r = requests.get(f'https://framatome-career.talent-soft.com/offre-de-emploi/liste-offres.aspx?page={i}&LCID=1033')\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "\n",
    "        for x in soup.find_all('div', class_='ts-offer-card Layer'):\n",
    "                        row_scrap = []\n",
    "                        job_title = x.find('h3', attrs={'class' : 'ts-offer-card__title'}).text.replace('\\n', '').strip()\n",
    "                        job_link = x.find('h3', attrs={'class' : 'ts-offer-card__title'}).find('a')['href']\n",
    "                        company = \"Framatome\"\n",
    "                        departement = 'N/A'\n",
    "                        details = []\n",
    "                        for v in x.find('ul', attrs={'class' : 'ts-offer-card-content__list'}).find_all('li'): \n",
    "                            item = v.text\n",
    "                            details.append(item)\n",
    "\n",
    "                        row_scrap.append(job_title)\n",
    "                        row_scrap.append(job_link)\n",
    "                        row_scrap.append(company)\n",
    "                        row_scrap.append(departement)\n",
    "                        row_scrap.append(details)\n",
    "\n",
    "                        framatome_db.append(row_scrap)\n",
    "        i = i + 1\n",
    "\n",
    "    framatome_db = pd.DataFrame(framatome_db)\n",
    "    framatome_db = framatome_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    framatome_db['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(framatome_db)-1:\n",
    "        r = requests.get('https://framatome-career.talent-soft.com/' + framatome_db['link'][i])\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        try :\n",
    "            framatome_db['desc'][i] = soup.find('div', attrs={'class' : 'ts-offer-page__content'}).text\n",
    "        except :\n",
    "            framatome_db['desc'][i] = ''\n",
    "        i = i + 1\n",
    "    #df = pd.concat([df, framatome_db], axis=0)\n",
    "    print(\"Framatome Scrap Finished\")\n",
    "\n",
    "def scrapEngie():\n",
    "    engie_db = []\n",
    "\n",
    "    i = 1\n",
    "    while i <= 315:\n",
    "        r = requests.get(f'https://jobs.engie.com/jobs/search/76073636/page{i}')\n",
    "        soup = BeautifulSoup(r.content,'lxml')\n",
    "        for x in soup.find_all('div', class_='jlr_right_hldr'):\n",
    "            row_scrap = []\n",
    "            job_title = x.find('p').text.replace('\\n', '').strip()\n",
    "            job_link = x.find('a')['href']\n",
    "            company = \"Engie\"\n",
    "            departement = x.find('p', attrs={'class' : 'jlr_company'}).text.replace('\\n', '').strip()\n",
    "            details = []\n",
    "            for v in x.find_all('p', attrs={'class' : 'jlr_cat_loc'}): \n",
    "                item = v.text.replace('\\t', '').replace('\\n', '')\n",
    "                details.append(item)\n",
    "\n",
    "            row_scrap.append(job_title)\n",
    "            row_scrap.append(job_link)\n",
    "            row_scrap.append(company)\n",
    "            row_scrap.append(departement)\n",
    "            row_scrap.append(details)\n",
    "\n",
    "            engie_db.append(row_scrap)\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "    engie_db = pd.DataFrame(engie_db)\n",
    "    engie_db = engie_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    engie_db['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= 10: #len(engie_db)-1:\n",
    "        r = requests.get(engie_db['link'][i])\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        try :\n",
    "            engie_db['desc'][i] = soup.find('div', attrs={'id' : 'description_box'}).text\n",
    "        except :\n",
    "            engie_db['desc'][i] = ''\n",
    "        i = i + 1\n",
    "    #df = pd.concat([df, engie_db], axis=0)\n",
    "    print(\"Engie Scrap Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Richemont Scrap Finished\n",
      "Dassault Aviation Scrap Finished\n",
      "Air France Scrap Finished\n",
      "Sanofi Scrap Finished\n",
      "Hermes Scrap Finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6780c4a2c61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mscrapSanofi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscrapHermes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mscrapFramatome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mscrapEngie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e3df0c2fc91e>\u001b[0m in \u001b[0;36mscrapFramatome\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframatome_db\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://framatome-career.talent-soft.com/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mframatome_db\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'link'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mtry\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 decoded = self._decode(chunk, decode_content=decode_content,\n\u001b[1;32m    671\u001b[0m                                        flush_decoder=False)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mreturned_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    608\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1050\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1052\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrapRichemont()\n",
    "scrapDassaultAviation()\n",
    "scrapAirFrance()\n",
    "scrapSanofi()\n",
    "scrapHermes()\n",
    "scrapFramatome()\n",
    "scrapEngie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([richemont_job_db, dassaultAviation_db, airFrance_db,\n",
    "               sanofi_db, hermes_db, framatome_db, engie_db], axis=0)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('backup/backup_2112.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# Air Liquide Scrap\n",
    "# ---------------\n",
    "#    - Issue : redirect to homepage instead of career page\n",
    "\n",
    "#browser.get('https://www.airliquide.com/fr/carrieres/offres-emploi')\n",
    "#soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "#airLiquide_db = []\n",
    "#for x in soup.find_all('tr'):\n",
    "#    row_scrap = []\n",
    "#    job_title = x.find('a').text.replace('\\n', '').strip()\n",
    "#    job_link = x.find('h3', attrs={'class' : 'ts-offer-card__title'}).find('a')['href']\n",
    "#    company = \"Framatome\"\n",
    "#    departement = 'N/A'\n",
    "#    details = []\n",
    "#    for v in x.find('ul', attrs={'class' : 'ts-offer-card-content__list'}).find_all('li'): \n",
    "#        item = v.text\n",
    "#        details.append(item)\n",
    "\n",
    "#    row_scrap.append(job_title)\n",
    "#    row_scrap.append(job_link)\n",
    "#    row_scrap.append(company)\n",
    "#    row_scrap.append(departement)\n",
    "#    row_scrap.append(details)\n",
    "\n",
    "#    airLiquide_db.append(row_scrap)\n",
    "\n",
    "#airLiquide_db = pd.DataFrame(airLiquide_db)\n",
    "#airLiquide_db = airLiquide_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "#airLiquide_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.airliquide.com/fr/carrieres/offres-emploi\n",
    "https://jobsearch.alstom.com/search/?createNewAlert=false&q=&locationsearch=\n",
    "https://cc.wd3.myworkdayjobs.com/fr-FR/ChanelCareers\n",
    "https://jobs.danone.com/search/?createNewAlert=false&q=&locationsearch=&optionsFacetsDD_country=FR&optionsFacetsDD_facility=&optionsFacetsDD_department=Experienced+professionals\n",
    "https://careers.3ds.com/jobs?woc=%7B%22country%22%3A%5B%22country%2Ffrance%22%5D%7D&wocset=6\n",
    "http://careers.disneylandparis.com/en/management-business/supply-chain-procurement\n",
    "https://www.edf.fr/edf-recrute\n",
    "https://jobs.engie.com\n",
    "https://recrutement.fnacdarty.com/accueil.aspx?LCID=1036\n",
    "https://www.place-emploi-public.gouv.fr\n",
    "https://jobs.gecareers.com/global/en/search-results\n",
    "https://www.invivo-group.com/fr/nos-offres\n",
    "https://kering.wd3.myworkdayjobs.com/fr-FR/Kering?source=LinkedIn_Slots\n",
    "https://careers.loreal.com/en_US/jobs/SearchJobs/\n",
    "https://www.lisi-aerospace.com/en/join-us/careers/\n",
    "https://www.lvmh.fr/talents/nous-rejoindre/nos-offres/liste-des-offres/?job=&place=&experience=&activity=&contract=&reference=#gt_offers-results\n",
    "https://www.mbda-systems.com/jobs/?gestmax%5Bvac_sector%5D=&gestmax%5Bvac_localisation%5D=001&gestmax%5Bvac_job_type%5D=\n",
    "https://jobs.moncler.com/search/?createNewAlert=false&q=&locationsearch=\n",
    "https://motul-recrute.talent-soft.com/job/list-of-jobs.aspx\n",
    "https://www.naval-group.com/fr/nous-rejoindre-85?keywords=&offerFamilyCategory=&contractType=&country=&city=&op=Rechercher&form_build_id=form-NzrJ7AsvKwvEKPwLDA2P5Qu6e3T6EKUpkTDoHGZS6Is&form_id=talent_soft_offers_filters_form#offer-list-content\n",
    "https://nexter-recrutement.profils.org/accueil.aspx?LCID=1036\n",
    "https://orange.jobs/jobs/search.do?keyword=\n",
    "https://pernodricard.wd3.myworkdayjobs.com/fr-FR/pernod-ricard\n",
    "https://jobs.groupe-psa.com/offre-de-emploi/liste-offres.aspx?mode=layer&lcid=1036&facet_JobDescription_Contract=577\n",
    "https://renault.referrals.selectminds.com/\n",
    "https://www.safran-group.com/jobs\n",
    "https://joinus.saint-gobain.com/fr\n",
    "https://www.sodern.com/website/fr/ref/Carri√®res_262.html\n",
    "https://hris-suez.csod.com/ats/careersite/search.aspx?site=8&c=hris-suez&sid=%5e%5e%5eHJe5gko1mldbDMyZ8oI9Lw%3d%3d\n",
    "https://careers.hr.technipfmc.com\n",
    "https://emploi.thalesgroup.com/recherche-d%27offres\n",
    "https://krb-sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=30080&siteid=6559#home\n",
    "https://career012.successfactors.eu/career?company=VALLOUREC&site=VjItcmY2YVFFcnJMYWhIb3RmMzhTYU9Ldz09\n",
    "https://emplois.vinci.com/recherche-d%27offres\n",
    "https://www.nestle.fr/jobs/search-jobs?keyword=&country=FR&location=&career_area=All&company=All\n",
    "https://www.smcp.com/fr/talents/offres-d-emploi/?keywords=&geographicalLocation=22&offerCountry=79&offerRegion=&organisation=&offerFamilyCategory=&contractType=&experienceLevel=\n",
    "https://pfizer.wd1.myworkdayjobs.com/PfizerCareers/5/refreshFacet/318c8bb6f553100021d223d9780d30be\n",
    "https://careers.faurecia.com/search/?createNewAlert=false&q=&locationsearch=france&optionsFacetsDD_customfield3=&optionsFacetsDD_country=&optionsFacetsDD_shifttype=Unlimited\n",
    "https://www.emploi.sncf.com/nos-offres/contrat/577-578/localisation/40629/\n",
    "https://careers.ratpdev.com/offre-de-emploi/liste-offres.aspx?page=3&LCID=1036\n",
    "https://arianegroup.wd3.myworkdayjobs.com/EXTERNALALL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
