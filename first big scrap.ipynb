{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config\n",
    "\n",
    "# Create Backup\n",
    "# --------------------\n",
    "\n",
    "os.system(\"mkdir backup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Richemont Scrapper\n",
    "\n",
    "richemont_job_db = []\n",
    "\n",
    "browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "browser.get('https://jobs.richemont.com/search/?q=&sortColumn=referencedate&sortDirection=desc&optionsFacetsDD_country=FR&startrow=1')\n",
    "\n",
    "soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "for x in soup.find_all('tr', attrs={'class' : 'data-row clickable'}):\n",
    "    row_scrap = []\n",
    "    job_title = x.find('span', attrs={'class' : 'jobTitle'}).text.replace('\\n', '')\n",
    "    job_link = x.find('span', attrs={'class' : 'jobTitle'}).find('a')['href']\n",
    "    company = x.find('span', attrs={'class' : 'jobFacility'}).text.replace('\\n', '')\n",
    "    departement = x.find('span', attrs={'class' : 'jobDepartment'}).text.replace('\\n', '')\n",
    "    location = x.find('span', attrs={'class' : 'jobLocation'}).text.replace('\\n', '').strip()\n",
    "    \n",
    "    row_scrap.append(job_title)\n",
    "    row_scrap.append(job_link)\n",
    "    row_scrap.append(company)\n",
    "    row_scrap.append(departement)\n",
    "    row_scrap.append(location)\n",
    "    \n",
    "    richemont_job_db.append(row_scrap)\n",
    "\n",
    "i = 14\n",
    "while i <= int(soup.find('a', class_='paginationItemLast')['href'][-3:]) :\n",
    "    browser.get(f'https://jobs.richemont.com/search/?q=&sortColumn=referencedate&sortDirection=desc&optionsFacetsDD_country=FR&startrow={i}')\n",
    "\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "    \n",
    "    for x in soup.find_all('tr', attrs={'class' : 'data-row clickable'}):\n",
    "        row_scrap = []\n",
    "        job_title = x.find('span', attrs={'class' : 'jobTitle'}).text.replace('\\n', '')\n",
    "        job_link = x.find('span', attrs={'class' : 'jobTitle'}).find('a')['href']\n",
    "        company = x.find('span', attrs={'class' : 'jobFacility'}).text.replace('\\n', '')\n",
    "        departement = x.find('span', attrs={'class' : 'jobDepartment'}).text.replace('\\n', '')\n",
    "        location = x.find('span', attrs={'class' : 'jobLocation'}).text.replace('\\n', '').strip()\n",
    "\n",
    "        row_scrap.append(job_title)\n",
    "        row_scrap.append(job_link)\n",
    "        row_scrap.append(company)\n",
    "        row_scrap.append(departement)\n",
    "        row_scrap.append(location)\n",
    "\n",
    "        richemont_job_db.append(row_scrap)\n",
    "    \n",
    "    i = i + 14\n",
    "    \n",
    "richemont_job_db = pd.DataFrame(richemont_job_db)\n",
    "richemont_job_db = richemont_job_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\",\n",
    "                                                    3 : \"Department\", 4 : \"Location\"})\n",
    "\n",
    "richemont_job_db_copy = richemont_job_db\n",
    "richemont_job_db_copy['desc'] = ''\n",
    "\n",
    "# Add Desc to job offer\n",
    "# add https://jobs.richemont.com before links to connect\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i <= len(richemont_job_db_copy)-1:\n",
    "    browser.get('https://jobs.richemont.com' + richemont_job_db_copy['link'][i])\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "    richemont_job_db_copy['desc'][i] = soup.find('span', class_=\"jobdescription\").text\n",
    "    i = i + 1\n",
    "richemont_job_db_copy.head()\n",
    "\n",
    "richemont_job_db_copy.to_csv('backup/richemont_db.csv')\n",
    "richemont_job_db_copy.to_json('backup/richemont_db.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dassault Aviation\n",
    "\n",
    "dassaultAviation_db = []\n",
    "\n",
    "browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "\n",
    "i = 1\n",
    "while i <= 10:\n",
    "    browser.get(f'https://carriere.dassault-aviation.com/offre-de-emploi/liste-offres.aspx?page={i}&LCID=1036')\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "    for x in soup.find_all('li', class_='ts-offer-list-item'):\n",
    "            row_scrap = []\n",
    "            job_title = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'}).text.replace('\\n', '').strip()\n",
    "            job_link = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'})['href']\n",
    "            company = \"Dassault Aviation\"\n",
    "            departement = 'N/A'\n",
    "            details = x.find('ul', attrs={'class' : 'ts-offer-list-item__description'}).find_all('li')\n",
    "\n",
    "            row_scrap.append(job_title)\n",
    "            row_scrap.append(job_link)\n",
    "            row_scrap.append(company)\n",
    "            row_scrap.append(departement)\n",
    "            row_scrap.append(details)\n",
    "\n",
    "            dassaultAviation_db.append(row_scrap)\n",
    "    \n",
    "    i = i + 1\n",
    "\n",
    "dassaultAviation_db = pd.DataFrame(dassaultAviation_db)\n",
    "dassaultAviation_db = dassaultAviation_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "dassaultAviation_db_copy = dassaultAviation_db\n",
    "dassaultAviation_db_copy['desc'] = ''\n",
    "\n",
    "# Add Desc to job offer\n",
    "# add https://carriere.dassault-aviation.com before links to connect\n",
    "\n",
    "i = 0\n",
    "while i <= len(dassaultAviation_db_copy)-1:\n",
    "    browser.get('https://carriere.dassault-aviation.com' + dassaultAviation_db_copy['link'][i])\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "    dassaultAviation_db_copy['desc'][i] = soup.find('div', attrs={'id' : 'contenu-ficheoffre'}).text\n",
    "    i = i + 1\n",
    "\n",
    "dassaultAviation_db_copy.to_csv('backup/dassaultAviation_db.csv')\n",
    "dassaultAviation_db_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Air France\n",
    "\n",
    "browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "\n",
    "airFrance_db = []\n",
    "\n",
    "browser.get('https://recrutement.airfrance.com/offre-de-emploi/liste-offres.aspx')\n",
    "soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "for x in soup.find_all('li', class_='ts-offer-list-item'):\n",
    "            row_scrap = []\n",
    "            job_title = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'}).text.replace('\\n', '').strip()\n",
    "            job_link = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'})['href']\n",
    "            company = \"Air France\"\n",
    "            departement = 'N/A'\n",
    "            details = x.find('ul', attrs={'class' : 'ts-offer-list-item__description'}).find_all('li')\n",
    "\n",
    "            row_scrap.append(job_title)\n",
    "            row_scrap.append(job_link)\n",
    "            row_scrap.append(company)\n",
    "            row_scrap.append(departement)\n",
    "            row_scrap.append(details)\n",
    "\n",
    "            airFrance_db.append(row_scrap)\n",
    "\n",
    "airFrance_db = pd.DataFrame(airFrance_db)\n",
    "airFrance_db = airFrance_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "airFrance_db_copy = airFrance_db\n",
    "airFrance_db_copy['desc'] = ''\n",
    "\n",
    "i = 0\n",
    "while i <= len(airFrance_db_copy)-1:\n",
    "    browser.get('https://recrutement.airfrance.com' + airFrance_db_copy['link'][i])\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "    airFrance_db_copy['desc'][i] = soup.find('div', attrs={'id' : 'contenu-ficheoffre'}).text\n",
    "    i = i + 1\n",
    "\n",
    "airFrance_db_copy.to_csv('backup/airFrance_db.csv')\n",
    "airFrance_db_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>link</th>\n",
       "      <th>Company</th>\n",
       "      <th>Department</th>\n",
       "      <th>Location</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STAGE – Développeur Web Full Stack H/F</td>\n",
       "      <td>/offre-de-emploi/emploi-stage-developpeur-web-...</td>\n",
       "      <td>Air France</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[[Convention de stage], [Occitanie]]</td>\n",
       "      <td>\\n\\n                Informations générales\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STAGE - Ingénierie Analyse des Paramètres Enre...</td>\n",
       "      <td>/offre-de-emploi/emploi-stage-ingenierie-analy...</td>\n",
       "      <td>Air France</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[[Convention de stage], [Ile-de-France]]</td>\n",
       "      <td>\\n\\n                Informations générales\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alternance – Développeur Front-End H/F</td>\n",
       "      <td>/offre-de-emploi/emploi-alternance-developpeur...</td>\n",
       "      <td>Air France</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[[Alternance et apprentissage], [Provence-Alpe...</td>\n",
       "      <td>\\nDescription du poste\\n\\tIntitulé du poste\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALTERNANCE – Assistance à Maîtrise d'Ouvrage -...</td>\n",
       "      <td>/offre-de-emploi/emploi-alternance-assistance-...</td>\n",
       "      <td>Air France</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[[Alternance et apprentissage], [Ile-de-France]]</td>\n",
       "      <td>\\n\\n                Informations générales\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juriste HOP! CDD H/F</td>\n",
       "      <td>/offre-de-emploi/emploi-juriste-hop-cdd-h-f_11...</td>\n",
       "      <td>Air France</td>\n",
       "      <td>N/A</td>\n",
       "      <td>[[CDD], [Pays de la Loire]]</td>\n",
       "      <td>\\n\\n                Informations générales\\n  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position  \\\n",
       "0             STAGE – Développeur Web Full Stack H/F   \n",
       "1  STAGE - Ingénierie Analyse des Paramètres Enre...   \n",
       "2             Alternance – Développeur Front-End H/F   \n",
       "3  ALTERNANCE – Assistance à Maîtrise d'Ouvrage -...   \n",
       "4                               Juriste HOP! CDD H/F   \n",
       "\n",
       "                                                link     Company Department  \\\n",
       "0  /offre-de-emploi/emploi-stage-developpeur-web-...  Air France        N/A   \n",
       "1  /offre-de-emploi/emploi-stage-ingenierie-analy...  Air France        N/A   \n",
       "2  /offre-de-emploi/emploi-alternance-developpeur...  Air France        N/A   \n",
       "3  /offre-de-emploi/emploi-alternance-assistance-...  Air France        N/A   \n",
       "4  /offre-de-emploi/emploi-juriste-hop-cdd-h-f_11...  Air France        N/A   \n",
       "\n",
       "                                            Location  \\\n",
       "0               [[Convention de stage], [Occitanie]]   \n",
       "1           [[Convention de stage], [Ile-de-France]]   \n",
       "2  [[Alternance et apprentissage], [Provence-Alpe...   \n",
       "3   [[Alternance et apprentissage], [Ile-de-France]]   \n",
       "4                        [[CDD], [Pays de la Loire]]   \n",
       "\n",
       "                                                desc  \n",
       "0  \\n\\n                Informations générales\\n  ...  \n",
       "1  \\n\\n                Informations générales\\n  ...  \n",
       "2  \\nDescription du poste\\n\\tIntitulé du poste\\nA...  \n",
       "3  \\n\\n                Informations générales\\n  ...  \n",
       "4  \\n\\n                Informations générales\\n  ...  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
