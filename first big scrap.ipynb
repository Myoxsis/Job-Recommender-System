{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config\n",
    "\n",
    "# Create Backup\n",
    "# --------------------\n",
    "\n",
    "os.system(\"mkdir backup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "#    []   scrapRichemont()                     #    []   scrapRichemont()\n",
    "#    []   scrapDassaultAviation()              #    []   scrapRichemont()\n",
    "#    []   scrapAirFrance()                     #    []   scrapRichemont()\n",
    "#    []   scrapSanofi()                        #    []   scrapRichemont()\n",
    "#    []   scrapHermes()                        #    []   scrapRichemont()\n",
    "#    []   scrapFramatome()                     #    []   scrapRichemont()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize function\n",
    "def scrapRichemont():\n",
    "    richemont_job_db = []\n",
    "\n",
    "    browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "    browser.get('https://jobs.richemont.com/search/?q=&sortColumn=referencedate&sortDirection=desc&optionsFacetsDD_country=FR&startrow=1')\n",
    "\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "    for x in soup.find_all('tr', attrs={'class' : 'data-row clickable'}):\n",
    "        row_scrap = []\n",
    "        job_title = x.find('span', attrs={'class' : 'jobTitle'}).text.replace('\\n', '')\n",
    "        job_link = x.find('span', attrs={'class' : 'jobTitle'}).find('a')['href']\n",
    "        company = x.find('span', attrs={'class' : 'jobFacility'}).text.replace('\\n', '')\n",
    "        departement = x.find('span', attrs={'class' : 'jobDepartment'}).text.replace('\\n', '')\n",
    "        location = x.find('span', attrs={'class' : 'jobLocation'}).text.replace('\\n', '').strip()\n",
    "\n",
    "        row_scrap.append(job_title)\n",
    "        row_scrap.append(job_link)\n",
    "        row_scrap.append(company)\n",
    "        row_scrap.append(departement)\n",
    "        row_scrap.append(location)\n",
    "\n",
    "        richemont_job_db.append(row_scrap)\n",
    "\n",
    "    i = 14\n",
    "    while i <= int(soup.find('a', class_='paginationItemLast')['href'][-3:]) :\n",
    "        browser.get(f'https://jobs.richemont.com/search/?q=&sortColumn=referencedate&sortDirection=desc&optionsFacetsDD_country=FR&startrow={i}')\n",
    "\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "        for x in soup.find_all('tr', attrs={'class' : 'data-row clickable'}):\n",
    "            row_scrap = []\n",
    "            job_title = x.find('span', attrs={'class' : 'jobTitle'}).text.replace('\\n', '')\n",
    "            job_link = x.find('span', attrs={'class' : 'jobTitle'}).find('a')['href']\n",
    "            company = x.find('span', attrs={'class' : 'jobFacility'}).text.replace('\\n', '')\n",
    "            departement = x.find('span', attrs={'class' : 'jobDepartment'}).text.replace('\\n', '')\n",
    "            location = x.find('span', attrs={'class' : 'jobLocation'}).text.replace('\\n', '').strip()\n",
    "\n",
    "            row_scrap.append(job_title)\n",
    "            row_scrap.append(job_link)\n",
    "            row_scrap.append(company)\n",
    "            row_scrap.append(departement)\n",
    "            row_scrap.append(location)\n",
    "\n",
    "            richemont_job_db.append(row_scrap)\n",
    "\n",
    "        i = i + 14\n",
    "\n",
    "    richemont_job_db = pd.DataFrame(richemont_job_db)\n",
    "    richemont_job_db = richemont_job_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\",\n",
    "                                                        3 : \"Department\", 4 : \"Location\"})\n",
    "\n",
    "    richemont_job_db_copy = richemont_job_db\n",
    "    richemont_job_db_copy['desc'] = ''\n",
    "\n",
    "    # Add Desc to job offer\n",
    "    # add https://jobs.richemont.com before links to connect\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i <= len(richemont_job_db_copy)-1:\n",
    "        browser.get('https://jobs.richemont.com' + richemont_job_db_copy['link'][i])\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        richemont_job_db_copy['desc'][i] = soup.find('span', class_=\"jobdescription\").text\n",
    "        i = i + 1\n",
    "\n",
    "    richemont_job_db_copy.to_csv('backup/richemont_db.csv')\n",
    "    richemont_job_db_copy.to_json('backup/richemont_db.json')\n",
    "    \n",
    "    richemont_job_db_copy.head()\n",
    "    \n",
    "def scrapDassaultAviation():\n",
    "    dassaultAviation_db = []\n",
    "\n",
    "    browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "\n",
    "    i = 1\n",
    "    while i <= 10:\n",
    "        browser.get(f'https://carriere.dassault-aviation.com/offre-de-emploi/liste-offres.aspx?page={i}&LCID=1036')\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "        for x in soup.find_all('li', class_='ts-offer-list-item'):\n",
    "                row_scrap = []\n",
    "                job_title = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'}).text.replace('\\n', '').strip()\n",
    "                job_link = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'})['href']\n",
    "                company = \"Dassault Aviation\"\n",
    "                departement = 'N/A'\n",
    "                details = x.find('ul', attrs={'class' : 'ts-offer-list-item__description'}).find_all('li')\n",
    "\n",
    "                row_scrap.append(job_title)\n",
    "                row_scrap.append(job_link)\n",
    "                row_scrap.append(company)\n",
    "                row_scrap.append(departement)\n",
    "                row_scrap.append(details)\n",
    "\n",
    "                dassaultAviation_db.append(row_scrap)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    dassaultAviation_db = pd.DataFrame(dassaultAviation_db)\n",
    "    dassaultAviation_db = dassaultAviation_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    dassaultAviation_db_copy = dassaultAviation_db\n",
    "    dassaultAviation_db_copy['desc'] = ''\n",
    "\n",
    "    # Add Desc to job offer\n",
    "    # add https://carriere.dassault-aviation.com before links to connect\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(dassaultAviation_db_copy)-1:\n",
    "        browser.get('https://carriere.dassault-aviation.com' + dassaultAviation_db_copy['link'][i])\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        dassaultAviation_db_copy['desc'][i] = soup.find('div', attrs={'id' : 'contenu-ficheoffre'}).text\n",
    "        i = i + 1\n",
    "\n",
    "    dassaultAviation_db_copy.to_csv('backup/dassaultAviation_db.csv')\n",
    "    dassaultAviation_db_copy.head()\n",
    "    \n",
    "def scrapAirFrance():\n",
    "    browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "\n",
    "    airFrance_db = []\n",
    "\n",
    "    browser.get('https://recrutement.airfrance.com/offre-de-emploi/liste-offres.aspx')\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "    for x in soup.find_all('li', class_='ts-offer-list-item'):\n",
    "                row_scrap = []\n",
    "                job_title = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'}).text.replace('\\n', '').strip()\n",
    "                job_link = x.find('a', attrs={'class' : 'ts-offer-list-item__title-link'})['href']\n",
    "                company = \"Air France\"\n",
    "                departement = 'N/A'\n",
    "                details = x.find('ul', attrs={'class' : 'ts-offer-list-item__description'}).find_all('li')\n",
    "\n",
    "                row_scrap.append(job_title)\n",
    "                row_scrap.append(job_link)\n",
    "                row_scrap.append(company)\n",
    "                row_scrap.append(departement)\n",
    "                row_scrap.append(details)\n",
    "\n",
    "                airFrance_db.append(row_scrap)\n",
    "\n",
    "    airFrance_db = pd.DataFrame(airFrance_db)\n",
    "    airFrance_db = airFrance_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    airFrance_db_copy = airFrance_db\n",
    "    airFrance_db_copy['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(airFrance_db_copy)-1:\n",
    "        browser.get('https://recrutement.airfrance.com' + airFrance_db_copy['link'][i])\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        airFrance_db_copy['desc'][i] = soup.find('div', attrs={'id' : 'contenu-ficheoffre'}).text\n",
    "        i = i + 1\n",
    "\n",
    "    airFrance_db_copy.to_csv('backup/airFrance_db.csv')\n",
    "    airFrance_db_copy.head()\n",
    "\n",
    "def scrapSanofi():\n",
    "    browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "    browser.get('https://fr.jobs.sanofi.com/recherche-d%27offres/?p=1')\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "    sanofi_db = []\n",
    "\n",
    "    i = 1\n",
    "    while i <= int(soup.find('input', class_='pagination-current')['max']):\n",
    "        browser.get(f'https://fr.jobs.sanofi.com/recherche-d%27offres/?p={i}')\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        for x in soup.find('ul', class_='unstyled-list job-list').find_all('li'):\n",
    "                    row_scrap = []\n",
    "                    job_title = x.find('h2', attrs={'class' : 'h3-style'}).text.replace('\\n', '').strip()\n",
    "                    job_link = x.find('a')['href']\n",
    "                    company = \"Sanofi\"\n",
    "                    departement = 'N/A'\n",
    "                    details = x.find('span', attrs={'class' : 'job-location'}).text\n",
    "\n",
    "                    row_scrap.append(job_title)\n",
    "                    row_scrap.append(job_link)\n",
    "                    row_scrap.append(company)\n",
    "                    row_scrap.append(departement)\n",
    "                    row_scrap.append(details)\n",
    "\n",
    "                    sanofi_db.append(row_scrap)\n",
    "\n",
    "        i = i + 1\n",
    "\n",
    "    sanofi_db = pd.DataFrame(sanofi_db)\n",
    "    sanofi_db = sanofi_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    sanofi_db_copy = sanofi_db\n",
    "    sanofi_db_copy['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(sanofi_db_copy)-1:\n",
    "        browser.get('https://fr.jobs.sanofi.com/' + sanofi_db_copy['link'][i])\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        try :\n",
    "            sanofi_db_copy['desc'][i] = soup.find('div', attrs={'class' : 'ats-description'}).text\n",
    "        except :\n",
    "            sanofi_db_copy['desc'][i] = ''\n",
    "        i = i + 1\n",
    "\n",
    "    sanofi_db_copy.to_csv('backup/sanofi_db.csv')\n",
    "    sanofi_db_copy.head()\n",
    "\n",
    "def scrapHermes():\n",
    "    browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "\n",
    "    browser.get('https://talents.hermes.com/fr/')\n",
    "    soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "    hermes_db = []\n",
    "\n",
    "    for x in soup.find_all('div', class_='card-block'):\n",
    "                    row_scrap = []\n",
    "                    job_title = x.find('h2', attrs={'class' : 'offer-description bd-highlight block-with-text'}).text.replace('\\n', '').strip()\n",
    "                    job_link = x.find('a')['href']\n",
    "                    company = \"Hermes\"\n",
    "                    departement = 'N/A'\n",
    "                    details = []\n",
    "                    for v in x.find('ul', attrs={'class' : 'offer-list_info'}).find_all('li'): \n",
    "                        item = v.text\n",
    "                        details.append(item)\n",
    "\n",
    "                    #details.append(details_item)\n",
    "\n",
    "                    row_scrap.append(job_title)\n",
    "                    row_scrap.append(job_link)\n",
    "                    row_scrap.append(company)\n",
    "                    row_scrap.append(departement)\n",
    "                    row_scrap.append(details)\n",
    "\n",
    "                    hermes_db.append(row_scrap)\n",
    "\n",
    "    hermes_db = pd.DataFrame(hermes_db)\n",
    "    hermes_db = hermes_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    hermes_db_copy = hermes_db\n",
    "    hermes_db_copy['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(hermes_db_copy)-1:\n",
    "        browser.get('https://talents.hermes.com/' + hermes_db_copy['link'][i])\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        try :\n",
    "            hermes_db_copy['desc'][i] = soup.find('div', attrs={'id' : 'detailOffer'}).text\n",
    "        except :\n",
    "            hermes_db_copy['desc'][i] = ''\n",
    "        i = i + 1\n",
    "\n",
    "    hermes_db_copy.to_csv('backup/hermes_db.csv')\n",
    "    hermes_db_copy.head()\n",
    "    \n",
    "def scrapFramatome():\n",
    "    browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')\n",
    "    framatome_db = []\n",
    "\n",
    "    i = 1\n",
    "    while i <= 44:\n",
    "        browser.get(f'https://framatome-career.talent-soft.com/offre-de-emploi/liste-offres.aspx?page={i}&LCID=1033')\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "\n",
    "        for x in soup.find_all('div', class_='ts-offer-card Layer'):\n",
    "                        row_scrap = []\n",
    "                        job_title = x.find('h3', attrs={'class' : 'ts-offer-card__title'}).text.replace('\\n', '').strip()\n",
    "                        job_link = x.find('h3', attrs={'class' : 'ts-offer-card__title'}).find('a')['href']\n",
    "                        company = \"Framatome\"\n",
    "                        departement = 'N/A'\n",
    "                        details = []\n",
    "                        for v in x.find('ul', attrs={'class' : 'ts-offer-card-content__list'}).find_all('li'): \n",
    "                            item = v.text\n",
    "                            details.append(item)\n",
    "\n",
    "                        row_scrap.append(job_title)\n",
    "                        row_scrap.append(job_link)\n",
    "                        row_scrap.append(company)\n",
    "                        row_scrap.append(departement)\n",
    "                        row_scrap.append(details)\n",
    "\n",
    "                        framatome_db.append(row_scrap)\n",
    "        i = i + 1\n",
    "\n",
    "    framatome_db = pd.DataFrame(framatome_db)\n",
    "    framatome_db = framatome_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "    framatome_db_copy = framatome_db\n",
    "    framatome_db_copy['desc'] = ''\n",
    "\n",
    "    i = 0\n",
    "    while i <= len(framatome_db_copy)-1:\n",
    "        browser.get('https://framatome-career.talent-soft.com/' + framatome_db_copy['link'][i])\n",
    "        soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "        try :\n",
    "            framatome_db_copy['desc'][i] = soup.find('div', attrs={'class' : 'ts-offer-page__content'}).text\n",
    "        except :\n",
    "            framatome_db_copy['desc'][i] = ''\n",
    "        i = i + 1\n",
    "\n",
    "    framatome_db_copy.to_csv('backup/framatome_db.csv')\n",
    "    framatome_db_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrapDassaultAviation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('/Users/maxime_alain/Downloads/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.get('https://jobs.engie.com/jobs/search/76073636')\n",
    "soup = BeautifulSoup(browser.page_source,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>link</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chargé d'affaires H/F</td>\n",
       "      <td>https://jobs.engie.com/jobs/charg%C3%A9-daffai...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alternant Technicien d’Etudes Projet en Sécuri...</td>\n",
       "      <td>https://jobs.engie.com/jobs/alternant-technici...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chef de Projet TCE (H/F)</td>\n",
       "      <td>https://jobs.engie.com/jobs/chef-de-projet-tce...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Responsable de centre de profit</td>\n",
       "      <td>https://jobs.engie.com/jobs/responsable-de-cen...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Technicien d’Etudes Exécution en Génie Climati...</td>\n",
       "      <td>https://jobs.engie.com/jobs/technicien-d%E2%80...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analista de Gestão de Riscos III - ENGIE Soluç...</td>\n",
       "      <td>https://jobs.engie.com/jobs/analista-de-gest%C...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Préparateur H/F</td>\n",
       "      <td>https://jobs.engie.com/jobs/pr%C3%A9parateur-h...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Responsable d'affaires (H/F)</td>\n",
       "      <td>https://jobs.engie.com/jobs/responsable-daffai...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MECANICIEN LEVAGEUR (H/F)</td>\n",
       "      <td>https://jobs.engie.com/jobs/mecanicien-levageu...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHEF.FE D'EQUIPE (H/F) Vienne</td>\n",
       "      <td>https://jobs.engie.com/jobs/chef-fe-dequipe-h-...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Position  \\\n",
       "0                              Chargé d'affaires H/F   \n",
       "1  Alternant Technicien d’Etudes Projet en Sécuri...   \n",
       "2                           Chef de Projet TCE (H/F)   \n",
       "3                    Responsable de centre de profit   \n",
       "4  Technicien d’Etudes Exécution en Génie Climati...   \n",
       "5  Analista de Gestão de Riscos III - ENGIE Soluç...   \n",
       "6                                    Préparateur H/F   \n",
       "7                       Responsable d'affaires (H/F)   \n",
       "8                          MECANICIEN LEVAGEUR (H/F)   \n",
       "9                      CHEF.FE D'EQUIPE (H/F) Vienne   \n",
       "\n",
       "                                                link Company  \n",
       "0  https://jobs.engie.com/jobs/charg%C3%A9-daffai...      []  \n",
       "1  https://jobs.engie.com/jobs/alternant-technici...      []  \n",
       "2  https://jobs.engie.com/jobs/chef-de-projet-tce...      []  \n",
       "3  https://jobs.engie.com/jobs/responsable-de-cen...      []  \n",
       "4  https://jobs.engie.com/jobs/technicien-d%E2%80...      []  \n",
       "5  https://jobs.engie.com/jobs/analista-de-gest%C...      []  \n",
       "6  https://jobs.engie.com/jobs/pr%C3%A9parateur-h...      []  \n",
       "7  https://jobs.engie.com/jobs/responsable-daffai...      []  \n",
       "8  https://jobs.engie.com/jobs/mecanicien-levageu...      []  \n",
       "9  https://jobs.engie.com/jobs/chef-fe-dequipe-h-...      []  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engie_db = []\n",
    "\n",
    "for x in soup.find_all('div', class_='jlr_right_hldr'):\n",
    "    row_scrap = []\n",
    "    job_title = x.find('p').text.replace('\\n', '').strip()\n",
    "    job_link = x.find('a')['href']\n",
    "    company = \"Framatome\"\n",
    "    #departement = 'N/A'\n",
    "    details = []\n",
    "    for v in x.find('p', attrs={'class' : 'jlr_cat_loc'}).find_all('li'): \n",
    "        item = v.text\n",
    "        details.append(item)\n",
    "\n",
    "    row_scrap.append(job_title)\n",
    "    row_scrap.append(job_link)\n",
    "    #row_scrap.append(company)\n",
    "    #row_scrap.append(departement)\n",
    "    row_scrap.append(details)\n",
    "\n",
    "    engie_db.append(row_scrap)\n",
    "\n",
    "\n",
    "engie_db = pd.DataFrame(engie_db)\n",
    "engie_db = engie_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "engie_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------\n",
    "# Air Liquide Scrap\n",
    "# ---------------\n",
    "#    - Issue : redirect to homepage instead of career page\n",
    "\n",
    "#browser.get('https://www.airliquide.com/fr/carrieres/offres-emploi')\n",
    "#soup = BeautifulSoup(browser.page_source,'lxml')\n",
    "#airLiquide_db = []\n",
    "#for x in soup.find_all('tr'):\n",
    "#    row_scrap = []\n",
    "#    job_title = x.find('a').text.replace('\\n', '').strip()\n",
    "#    job_link = x.find('h3', attrs={'class' : 'ts-offer-card__title'}).find('a')['href']\n",
    "#    company = \"Framatome\"\n",
    "#    departement = 'N/A'\n",
    "#    details = []\n",
    "#    for v in x.find('ul', attrs={'class' : 'ts-offer-card-content__list'}).find_all('li'): \n",
    "#        item = v.text\n",
    "#        details.append(item)\n",
    "\n",
    "#    row_scrap.append(job_title)\n",
    "#    row_scrap.append(job_link)\n",
    "#    row_scrap.append(company)\n",
    "#    row_scrap.append(departement)\n",
    "#    row_scrap.append(details)\n",
    "\n",
    "#    airLiquide_db.append(row_scrap)\n",
    "\n",
    "#airLiquide_db = pd.DataFrame(airLiquide_db)\n",
    "#airLiquide_db = airLiquide_db.rename(columns={0 : \"Position\", 1 : \"link\", 2 : \"Company\", 3 : \"Department\", 4 : \"Location\"}) #\n",
    "#airLiquide_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://www.airliquide.com/fr/carrieres/offres-emploi\n",
    "https://jobsearch.alstom.com/search/?createNewAlert=false&q=&locationsearch=\n",
    "https://cc.wd3.myworkdayjobs.com/fr-FR/ChanelCareers\n",
    "https://jobs.danone.com/search/?createNewAlert=false&q=&locationsearch=&optionsFacetsDD_country=FR&optionsFacetsDD_facility=&optionsFacetsDD_department=Experienced+professionals\n",
    "https://careers.3ds.com/jobs?woc=%7B%22country%22%3A%5B%22country%2Ffrance%22%5D%7D&wocset=6\n",
    "http://careers.disneylandparis.com/en/management-business/supply-chain-procurement\n",
    "https://www.edf.fr/edf-recrute\n",
    "https://jobs.engie.com\n",
    "https://recrutement.fnacdarty.com/accueil.aspx?LCID=1036\n",
    "https://www.place-emploi-public.gouv.fr\n",
    "https://jobs.gecareers.com/global/en/search-results\n",
    "https://www.invivo-group.com/fr/nos-offres\n",
    "https://kering.wd3.myworkdayjobs.com/fr-FR/Kering?source=LinkedIn_Slots\n",
    "https://careers.loreal.com/en_US/jobs/SearchJobs/\n",
    "https://www.lisi-aerospace.com/en/join-us/careers/\n",
    "https://www.lvmh.fr/talents/nous-rejoindre/nos-offres/liste-des-offres/?job=&place=&experience=&activity=&contract=&reference=#gt_offers-results\n",
    "https://www.mbda-systems.com/jobs/?gestmax%5Bvac_sector%5D=&gestmax%5Bvac_localisation%5D=001&gestmax%5Bvac_job_type%5D=\n",
    "https://jobs.moncler.com/search/?createNewAlert=false&q=&locationsearch=\n",
    "https://motul-recrute.talent-soft.com/job/list-of-jobs.aspx\n",
    "https://www.naval-group.com/fr/nous-rejoindre-85?keywords=&offerFamilyCategory=&contractType=&country=&city=&op=Rechercher&form_build_id=form-NzrJ7AsvKwvEKPwLDA2P5Qu6e3T6EKUpkTDoHGZS6Is&form_id=talent_soft_offers_filters_form#offer-list-content\n",
    "https://nexter-recrutement.profils.org/accueil.aspx?LCID=1036\n",
    "https://orange.jobs/jobs/search.do?keyword=\n",
    "https://pernodricard.wd3.myworkdayjobs.com/fr-FR/pernod-ricard\n",
    "https://jobs.groupe-psa.com/offre-de-emploi/liste-offres.aspx?mode=layer&lcid=1036&facet_JobDescription_Contract=577\n",
    "https://renault.referrals.selectminds.com/\n",
    "https://www.safran-group.com/jobs\n",
    "https://joinus.saint-gobain.com/fr\n",
    "https://www.sodern.com/website/fr/ref/Carrières_262.html\n",
    "https://hris-suez.csod.com/ats/careersite/search.aspx?site=8&c=hris-suez&sid=%5e%5e%5eHJe5gko1mldbDMyZ8oI9Lw%3d%3d\n",
    "https://careers.hr.technipfmc.com\n",
    "https://emploi.thalesgroup.com/recherche-d%27offres\n",
    "https://krb-sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=30080&siteid=6559#home\n",
    "https://career012.successfactors.eu/career?company=VALLOUREC&site=VjItcmY2YVFFcnJMYWhIb3RmMzhTYU9Ldz09\n",
    "https://emplois.vinci.com/recherche-d%27offres\n",
    "https://www.nestle.fr/jobs/search-jobs?keyword=&country=FR&location=&career_area=All&company=All\n",
    "https://www.smcp.com/fr/talents/offres-d-emploi/?keywords=&geographicalLocation=22&offerCountry=79&offerRegion=&organisation=&offerFamilyCategory=&contractType=&experienceLevel=\n",
    "https://pfizer.wd1.myworkdayjobs.com/PfizerCareers/5/refreshFacet/318c8bb6f553100021d223d9780d30be\n",
    "https://careers.faurecia.com/search/?createNewAlert=false&q=&locationsearch=france&optionsFacetsDD_customfield3=&optionsFacetsDD_country=&optionsFacetsDD_shifttype=Unlimited\n",
    "https://www.emploi.sncf.com/nos-offres/contrat/577-578/localisation/40629/\n",
    "https://careers.ratpdev.com/offre-de-emploi/liste-offres.aspx?page=3&LCID=1036\n",
    "https://arianegroup.wd3.myworkdayjobs.com/EXTERNALALL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
